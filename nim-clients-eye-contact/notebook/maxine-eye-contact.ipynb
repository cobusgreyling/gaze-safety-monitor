{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# NVIDIA Maxine Eye Contact - Python Notebook\n",
        "\n",
        "This notebook demonstrates how to use the NVIDIA Maxine Eye Contact service with Python. The Eye Contact feature estimates gaze angles in video and redirects them to create natural, frontal eye contact.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The Eye Contact service processes MP4 video files and outputs enhanced videos with corrected gaze direction. This implementation provides:\n",
        "\n",
        "- **Service Integration**: Connect to Maxine Eye Contact services\n",
        "- **Default Configuration**: Uses standard parameters with easy customization\n",
        "- **Streaming Support**: gRPC bi-directional streaming support.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- **Input**: MP4 files with H.264 video codec (audio optional), videos with Variable Frame Rate (VFR) are not supported.\n",
        "- **Output**: MP4 files with H.264 video codec (preserves original audio)\n",
        "- **Service**: Access to a running Maxine Eye Contact service instance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Installation\n",
        "\n",
        "**Requirements:**\n",
        "- Python 3.10+ \n",
        "- pip package manager\n",
        "- gRPC dependencies from the requirements.txt file\n",
        "\n",
        "```bash\n",
        "pip install -r ../requirements.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Service Configuration\n",
        "\n",
        "Configure the connection to your NVIDIA Maxine Eye Contact NIM service. The service can be running on your machine or on a remote server accessible from your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "\n",
        "# Setup paths for Eye Contact modules\n",
        "SCRIPT_PATH = str(pathlib.Path().resolve())\n",
        "sys.path.append(os.path.join(SCRIPT_PATH, \"../scripts\"))\n",
        "sys.path.append(os.path.join(SCRIPT_PATH, \"../interfaces\"))\n",
        "sys.path.append(os.path.join(SCRIPT_PATH, \"../../..\"))\n",
        "\n",
        "# Service connection configuration\n",
        "SERVICE_HOST = \"localhost\"  # Update to your service host\n",
        "SERVICE_PORT = 8001         # Update to your service port\n",
        "SERVICE_TARGET = f\"{SERVICE_HOST}:{SERVICE_PORT}\"\n",
        "\n",
        "print(f\"Service target configured: {SERVICE_TARGET}\")\n",
        "print(f\"Python paths configured for Eye Contact modules\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import grpc\n",
        "import time\n",
        "from typing import Iterator\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Import Eye Contact modules\n",
        "from config import EyeContactConfig\n",
        "from constants import DATA_CHUNK_SIZE\n",
        "import eyecontact_pb2\n",
        "import eyecontact_pb2_grpc\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "Define functions for processing video data and communicating with the Eye Contact service. These functions handle the bi-directional gRPC streaming protocol used by the Eye Contact service.\n",
        "\n",
        "### Function Overview\n",
        "\n",
        "The Eye Contact service uses bi-directional gRPC streaming over a channel. The implementation consists of two main functions:\n",
        "\n",
        "1. **Request Generator**: A Python iterator that yields request chunks to stream to the service\n",
        "2. **Response Processor**: A function that processes the incoming gRPC data stream and writes the output file\n",
        "\n",
        "### Streaming Protocol Details\n",
        "\n",
        "- **First Stream Item**: Configuration object that sets the Eye Contact feature parameters\n",
        "- **Subsequent Items**: Video data chunks (64KB each) containing the input MP4 file\n",
        "- **Response Stream**: Video data chunks containing the processed output MP4 file\n",
        "- **Configuration Echo**: If parameters are sent, the first response item is an echo that should be skipped\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_request_for_inference(\n",
        "    input_filepath: str, \n",
        "    config_params: dict | None = None\n",
        ") -> Iterator[eyecontact_pb2.RedirectGazeRequest]:\n",
        "    \"\"\"Generate streaming requests for the Eye Contact service.\n",
        "\n",
        "    Args:\n",
        "        input_filepath: Path to the input MP4 video file (H.264 codec recommended)\n",
        "        config_params: Dictionary of Eye Contact configuration parameters. If None or empty,\n",
        "                      default values will be used by the service.\n",
        "\n",
        "    Yields:\n",
        "        RedirectGazeRequest messages containing either:\n",
        "        - Configuration object (first yield, only if config_params provided)\n",
        "        - Video file data chunks (64KB each)\n",
        "        \n",
        "    Raises:\n",
        "        IOError: If the input file cannot be read due to permissions or I/O errors\n",
        "        FileNotFoundError: If the input file doesn't exist at the specified path\n",
        "        \n",
        "    Example:\n",
        "        config = {\"eye_size_sensitivity\": 4, \"detect_closure\": 1}\n",
        "        for request in generate_request_for_inference(\"video.mp4\", config):\n",
        "            # Process each request chunk\n",
        "            pass\n",
        "    \"\"\"\n",
        "    \n",
        "    # Send configuration first\n",
        "    if config_params:\n",
        "        print(\"Sending configuration parameters\")\n",
        "        yield eyecontact_pb2.RedirectGazeRequest(\n",
        "            config=eyecontact_pb2.RedirectGazeConfig(**config_params)\n",
        "        )\n",
        "    \n",
        "    # Send video data in chunks with progress tracking\n",
        "    print(\"Sending video data\")\n",
        "    try:\n",
        "        file_size = os.path.getsize(input_filepath)\n",
        "        chunk_count = 0\n",
        "        bytes_sent = 0\n",
        "        \n",
        "        with open(input_filepath, \"rb\") as fd:\n",
        "            with tqdm(total=file_size, unit='B', unit_scale=True, \n",
        "                     desc=\"Uploading\", leave=False) as pbar:\n",
        "                \n",
        "                while True:\n",
        "                    buffer = fd.read(DATA_CHUNK_SIZE)\n",
        "                    if not buffer:\n",
        "                        break\n",
        "                        \n",
        "                    chunk_count += 1\n",
        "                    bytes_sent += len(buffer)\n",
        "                    pbar.update(len(buffer))\n",
        "                    \n",
        "                    yield eyecontact_pb2.RedirectGazeRequest(video_file_data=buffer)\n",
        "                    \n",
        "        print(f\"Upload complete: {chunk_count} chunks ({bytes_sent / (1024*1024):.1f} MB)\")\n",
        "        \n",
        "    except IOError as e:\n",
        "        print(f\"Error reading input file: {e}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create the configuration for Eye Contact service request processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_eye_contact_config() -> dict:\n",
        "    \"\"\"Create Eye Contact configuration with default parameters.\n",
        "    \n",
        "    Uses the standard default values from the Eye Contact service configuration.\n",
        "    Users can modify these values as needed for your use case.\n",
        "    Detailed documentation about the parameters can be found below:\n",
        "    \n",
        "    Returns:\n",
        "        Configuration dictionary for the Eye Contact service\n",
        "    \"\"\"\n",
        "    \n",
        "    # Default configuration using values from constants.py\n",
        "    config = {\n",
        "        \"temporal\": 0xFFFFFFFF,                    # Enable temporal filtering\n",
        "        \"detect_closure\": 0,                       # Eye closure detection (0=disabled, 1=enabled)\n",
        "        \"eye_size_sensitivity\": 3,                 # Eye size sensitivity (range: 2-6)\n",
        "        \"enable_lookaway\": 0,                      # Natural look-away (0=disabled, 1=enabled)\n",
        "        \"lookaway_max_offset\": 5,                  # Max gaze offset for look-away (range: 1-10)\n",
        "        \"lookaway_interval_min\": 3,                # Min frames between look-aways (range: 1-600)\n",
        "        \"lookaway_interval_range\": 8,              # Look-away timing range (range: 1-600)\n",
        "        \"gaze_pitch_threshold_low\": 20.0,          # Gaze pitch correction start (range: 10-35)\n",
        "        \"gaze_pitch_threshold_high\": 30.0,         # Gaze pitch full correction (range: 10-35)\n",
        "        \"gaze_yaw_threshold_low\": 20.0,            # Gaze yaw correction start (range: 10-35)\n",
        "        \"gaze_yaw_threshold_high\": 30.0,           # Gaze yaw full correction (range: 10-35)\n",
        "        \"head_pitch_threshold_low\": 15.0,          # Head pitch correction start (range: 10-35)\n",
        "        \"head_pitch_threshold_high\": 25.0,         # Head pitch full correction (range: 10-35)\n",
        "        \"head_yaw_threshold_low\": 25.0,            # Head yaw correction start (range: 10-35)\n",
        "        \"head_yaw_threshold_high\": 30.0,           # Head yaw full correction (range: 10-35)\n",
        "        \"output_video_encoding\": eyecontact_pb2.OutputVideoEncoding(\n",
        "            lossy=eyecontact_pb2.LossyEncoding(\n",
        "                bitrate=20000000,                   # Video bitrate (20 Mbps)\n",
        "                idr_interval=8                     # IDR frame interval\n",
        "            )\n",
        "        )\n",
        "    }\n",
        "    \n",
        "    return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Function Usage Details\n",
        "\n",
        "#### Request Generation Process\n",
        "\n",
        "The `generate_request_for_inference` function implements a Python iterator that yields gRPC request chunks:\n",
        "\n",
        "1. **Configuration Phase**: If `config_params` is provided, the first yielded item is a `RedirectGazeConfig` object\n",
        "2. **Data Streaming Phase**: The input MP4 file is read in 64KB chunks and yielded as `RedirectGazeRequest` messages\n",
        "3. **Completion**: The iterator completes when the entire file has been streamed\n",
        "\n",
        "#### Response Processing\n",
        "\n",
        "The `write_output_file_from_response` function handles the service response:\n",
        "\n",
        "1. **Configuration Echo**: If configuration was sent, the first response item is an echo that should be skipped\n",
        "2. **Data Reception**: Subsequent responses contain `video_file_data` chunks\n",
        "3. **File Assembly**: Chunks are written sequentially to reconstruct the output MP4 file\n",
        "4. **Progress Tracking**: Real-time feedback shows chunks received and total data downloaded\n",
        "\n",
        "#### Error Handling\n",
        "\n",
        "Both functions include comprehensive error handling:\n",
        "- File validation before processing\n",
        "- I/O error detection and reporting  \n",
        "- Progress tracking for debugging\n",
        "- Graceful cleanup on failures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_output_file_from_response(\n",
        "    response_iter: Iterator[eyecontact_pb2.RedirectGazeResponse],\n",
        "    output_filepath: str,\n",
        ") -> None:\n",
        "    \"\"\"Write output video file from the incoming gRPC data stream.\n",
        "\n",
        "    Args:\n",
        "        response_iter: Iterator of RedirectGazeResponse messages from the gRPC service.\n",
        "                      Each message may contain video_file_data chunks.\n",
        "        output_filepath: Path where the output MP4 video file will be saved.\n",
        "                        The file will be created or overwritten if it exists.\n",
        "        \n",
        "    Raises:\n",
        "        IOError: If the output file cannot be written due to permissions or disk space issues\n",
        "        \n",
        "    Example:\n",
        "        responses = stub.RedirectGaze(request_stream)\n",
        "        write_output_file_from_response(responses, \"processed_video.mp4\")\n",
        "    \"\"\"\n",
        "    print(f\"Writing output: {output_filepath}\")\n",
        "    \n",
        "    chunk_count = 0\n",
        "    total_bytes = 0\n",
        "    \n",
        "    try:\n",
        "        with open(output_filepath, \"wb\") as fd:\n",
        "            # Progress bar for receiving video chunks\n",
        "            pbar = tqdm(desc=\"Receiving video chunks\", unit=\"chunks\", unit_scale=False, \n",
        "                       dynamic_ncols=True, leave=False,\n",
        "                       bar_format=\"{desc}: {n} chunks | {rate_fmt} | {postfix}\")\n",
        "            \n",
        "            try:\n",
        "                for response in response_iter:\n",
        "                    if response.HasField(\"video_file_data\"):\n",
        "                        chunk_data = response.video_file_data\n",
        "                        fd.write(chunk_data)\n",
        "                        \n",
        "                        chunk_count += 1\n",
        "                        total_bytes += len(chunk_data)\n",
        "                        \n",
        "                        pbar.update(1)\n",
        "                        pbar.set_postfix_str(f\"{total_bytes / (1024*1024):.1f} MB received\")\n",
        "            finally:\n",
        "                pbar.close()\n",
        "        \n",
        "        print(f\"Output complete: {chunk_count} chunks ({total_bytes / (1024*1024):.1f} MB total)\")\n",
        "        \n",
        "    except IOError as e:\n",
        "        print(f\"Error writing output file: {e}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Video Processing Example\n",
        "\n",
        "Process a video file with the Eye Contact service. Configure parameters based on your specific requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "input_filepath = \"../assets/sample_transactional.mp4\"      # Update with your input video path\n",
        "output_filepath = \"output.mp4\"     # Desired output video path\n",
        "\n",
        "# Create default configuration for Eye Contact service request processing\n",
        "config_params = create_eye_contact_config()\n",
        "\n",
        "# Process the video\n",
        "def process_video(input_path: str, output_path: str, config: dict) -> bool:\n",
        "    \"\"\"Process video with Eye Contact service.\n",
        "    \n",
        "    Returns:\n",
        "        True if processing succeeded, False otherwise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"\\nProcessing: {input_path}\")\n",
        "        print(f\"Connecting to service: {SERVICE_TARGET}\")\n",
        "            # Validate input file exists\n",
        "        if not os.path.exists(input_path):\n",
        "            raise FileNotFoundError(f\"Input file not found: {input_path}\")\n",
        "    \n",
        "        # Connect to service (use secure channel if needed)\n",
        "        with grpc.insecure_channel(SERVICE_TARGET) as channel:\n",
        "            stub = eyecontact_pb2_grpc.MaxineEyeContactServiceStub(channel)\n",
        "            \n",
        "            start_time = time.time()\n",
        "            \n",
        "            # Process video\n",
        "            responses = stub.RedirectGaze(\n",
        "                generate_request_for_inference(input_path, config)\n",
        "            )\n",
        "            \n",
        "            # Skip configuration echo response\n",
        "            next(responses)\n",
        "            \n",
        "            # Write output with progress tracking\n",
        "            write_output_file_from_response(responses, output_path)\n",
        "            \n",
        "            end_time = time.time()\n",
        "            processing_time = end_time - start_time\n",
        "            \n",
        "            print(f\"Processing complete in {processing_time:.1f}s\")\n",
        "            print(f\"Output saved: {output_path}\")\n",
        "            \n",
        "            return True\n",
        "            \n",
        "    except FileNotFoundError:\n",
        "        print(f\"Input file not found: {input_path}\")\n",
        "        print(\"   Please update 'input_filepath' with a valid video file path\")\n",
        "        return False\n",
        "    except grpc.RpcError as e:\n",
        "        print(f\"Service connection failed: {e}\")\n",
        "        print(f\"   Ensure the Eye Contact service is running at {SERVICE_TARGET}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Processing failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Execute processing\n",
        "success = process_video(input_filepath, output_filepath, config_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Configuration Parameters \n",
        "\n",
        "#### Encoding Options\n",
        "\n",
        "- `Lossless`: Enables lossless video encoding. This setting overrides any bitrate configuration to ensure maximum quality output, although it results in larger file sizes. Use this mode when quality is the top priority.\n",
        "   ```bash\n",
        "   python eye-contact.py --target 127.0.0.1:8001 --lossless\n",
        "   ```\n",
        "\n",
        "- `bitrate`: Sets the target bitrate for video encoding in bits per second (bps). Higher bitrates result in better video quality but larger file sizes. This allows balancing quality and file size by controlling the video bitrate. The default is 20,000,000 bps (20 Mbps). For example, setting `--bitrate 5000000` targets 5 Mbps encoding.\n",
        "   ```bash\n",
        "   python eye-contact.py --target 127.0.0.1:8001 --bitrate 5000000\n",
        "   ```\n",
        "\n",
        "- `idr-interval`: Sets the interval between instantaneous decoding refresh (IDR) frames in the encoded video. IDR frames are special I-frames that clear all reference buffers, allowing the video to be decoded from that point without needing previous frames. Lower values improve seeking accuracy, random access, and overall encoding quality but increase file size, while higher values reduce file size but may impact seeking performance and quality. The default is 8 frames.\n",
        "   ```bash\n",
        "   python eye-contact.py --target 127.0.0.1:8001 --idr-interval 10\n",
        "   ```\n",
        "\n",
        "- `custom-encoding-params`: Passes custom encoding parameters as a JSON string, that provides fine-grained control for expert users via JSON configuration. These parameters are used to configure properties of the GStreamer nvvideo4linux2 encoder plugin, allowing direct control over the underlying hardware encoder settings.\n",
        "   ```bash\n",
        "   python eye-contact.py --custom-encoding-params '{\"idrinterval\": 20, \"maxbitrate\": 3000000}'\n",
        "   ```\n",
        "\n",
        "**Note:** <span style=\"color:red\">Custom encoding parameters are for expert users who need fine-grained control over video encoding. Incorrect values can cause encoding failures or poor-quality output. To configure the nvenc encoder, refer to [Gst properties of the Gst-nvvideo4linux2 encoder plugin](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvvideo4linux2.html#:~:text=The%20following%20table%20summarizes%20the%20Gst%20properties%20of%20the%20Gst%2Dnvvideo4linux2%20encoder%20plugin).</span>\n",
        "\n",
        "### Arguments to Control Feature Behavior\n",
        "\n",
        "The following arguments affect the overall behavior of the feature, such as enabling or disabling temporal filtering or gaze redirection:\n",
        "\n",
        "- `temporal` - (UINT32) Flag to control temporal filtering (default `0xffffffff`). When set to true, the landmark computation for eye contact is temporally optimized.\n",
        "\n",
        "- `detect_closure` - (UINT32) Flag to toggle detection of eye closure and occlusion. If turned off, blink and occlusion detection turns off. This might be desirable during estimation-only mode if you still want to obtain gaze estimation in case of occlusion. Not recommended for gaze redirection. Value is either 0 or 1 (default 0).\n",
        "\n",
        "- `eye_size_sensitivity` - (UINT32) Eye size sensitivity parameter that modifies the blending parameters to use a larger region around the eyes for blending. Integer value from 2 to 6 (default 3).\n",
        "\n",
        "### Randomized Look Away Parameters\n",
        "\n",
        "A continuous redirection of gaze to look at the camera might give a perception of staring. Some users might find this effect unnatural or undesired. To occasionally break eye contact, you can enable randomized look away in gaze redirection. Although the gaze is always expected to redirect toward the camera within the range of operation, enabling look away makes the user occasionally break gaze lock to the camera with a micro-movement of the eyes at randomly chosen time intervals. The `enable_look_away` parameter must be set to true to enable this feature. Additionally, you can use the optional parameters `look_away_offset_max`, `look_away_interval_min`, and `look_away_interval_range` to tune the extent and frequency of look away.\n",
        "\n",
        "- `enable_lookaway` - (UINT32) Flag to toggle look away. If set to on, the eyes are redirected to look away for a random period occasionally to avoid staring. Value is either 0 or 1 (default 0).\n",
        "\n",
        "- `lookaway_max_offset` - (UINT32) Maximum value of gaze offset angle (degrees) during a random look away when look away is enabled. Requires `--enable_look_away` parameter to be set to true. Integer value from 1 to 10 (default 5).\n",
        "\n",
        "- `lookaway_interval_min` - (UINT32) Minimum limit for the number of frames at which random look away occurs when look away is enabled. Requires `--enable_look_away` parameter to be set to true. Integer value from 1 to 600 (default 3).\n",
        "\n",
        "- `lookaway_interval_range` - (UINT32) Range for picking the number of frames at which random look away occurs when look away is enabled. Requires `--enable_look_away` parameter to be set to true. Integer value from 1 to 600 (default 8).\n",
        "\n",
        "### Range Control\n",
        "\n",
        "The gaze redirection feature redirects the eyes to look at the camera within a certain range of head and eye motion in which eye contact is desired and looks natural. Beyond this range, the feature gradually transitions away from looking at the camera toward the estimated gaze and eventually turns off in a seamless manner. To provide for various use cases and user preferences, we provide range parameters for the user to control the range of gaze angles and head poses in which gaze redirection occurs and the range in which transition occurs before the redirection is turned off. These are optional parameters.\n",
        "\n",
        "`gaze_pitch_threshold_low` and `gaze_yaw_threshold_low` define the parameters for the pitch and yaw angles of the estimated gaze within which gaze is redirected toward the camera. Beyond these angles, redirected gaze transitions away from the camera and toward the estimated gaze, turning off redirection beyond `gaze_pitch_threshold_high` and `gaze_yaw_threshold_high` respectively.\n",
        "\n",
        "Similarly, `head_pitch_threshold_low` and `head_yaw_threshold_low` define the parameters for pitch and yaw angles of the head pose within which gaze is redirected toward the camera. Beyond these angles, redirected gaze transitions away from the camera and toward the estimated gaze, turning off redirection beyond `head_pitch_threshold_high` and `head_yaw_threshold_high`.\n",
        "\n",
        "- `gaze_pitch_threshold_low` - (FP32) Gaze pitch threshold (degrees) at which the redirection starts transitioning away from camera toward estimated gaze. Float value from 10 to 35 (default 20).\n",
        "\n",
        "- `gaze_pitch_threshold_high` - (FP32) Gaze pitch threshold (degrees) at which the redirection is equal to estimated gaze and the gaze redirection is turned off beyond this angle. Float value from 10 to 35 (default 30).\n",
        "\n",
        "- `gaze_yaw_threshold_low` - (FP32) Gaze yaw threshold (degrees) at which the redirection starts transitioning away from camera toward estimated gaze. Float value from 10 to 35 (default 20).\n",
        "\n",
        "- `gaze_yaw_threshold_high` - (FP32) Gaze yaw threshold (degrees) at which the redirection the redirection is equal to estimated gaze and the gaze redirection is turned off beyond this angle. Float value from 10 to 35 (default 30).\n",
        "\n",
        "- `head_pitch_threshold_low` - (FP32) Head pose pitch threshold (degrees) of the estimated head pose at which redirection starts transitioning away from camera and toward the estimated gaze. Float value from 10 to 35 (default 15).\n",
        "\n",
        "- `head_pitch_threshold_high` - (FP32) Head pose pitch threshold (degrees) of the estimated head pose at which redirection equals the estimated gaze and redirection is turned off beyond this angle. Float value from 10 to 35 (default 25).\n",
        "\n",
        "- `head_yaw_threshold_low` - (FP32) Head pose yaw threshold (degrees) at which the redirection starts transitioning away from camera toward estimated gaze. Float value from 10 to 35 (default 25).\n",
        "\n",
        "- `head_yaw_threshold_high` - (FP32) Head pose yaw threshold (degrees) of the estimated head pose at which redirection equals the estimated gaze and redirection is turned off beyond this angle. Float value from 10 to 35 (default 30).\n",
        "\n",
        "More details on customizing Eye Contact behavior based on your specific use case can found in the [Advanced Usage Section](https://docs.nvidia.com/nim/maxine/eye-contact/latest/advanced-usage.html)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
